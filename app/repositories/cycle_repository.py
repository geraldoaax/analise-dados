import glob
import logging
import os
import time
from datetime import datetime
from typing import Any, Dict, Optional

import pandas as pd

logger = logging.getLogger(__name__)


class CycleRepository:
    """Repository para acesso aos dados de ciclo com cache inteligente"""
    
    def __init__(self, data_path: str = 'CicloDetalhado'):
        self.data_path = data_path
        self._cache: Dict[str, Any] = {
            'raw_data': None,
            'processed_data': None,
            'last_check': None,
            'files_hash': None
        }
    
    def _get_files_hash(self) -> int:
        """Calcula hash dos arquivos para detectar mudan√ßas"""
        all_files = glob.glob(f"{self.data_path}/*.xlsx")
        
        # Filtrar arquivos tempor√°rios do Excel (que come√ßam com ~$)
        all_files = [f for f in all_files if not os.path.basename(f).startswith('~$')]
        
        files_info = []
        for filename in all_files:
            stat = os.stat(filename)
            files_info.append(f"{filename}:{stat.st_size}:{stat.st_mtime}")
        
        return hash(tuple(sorted(files_info)))
    
    def _load_excel_files(self) -> pd.DataFrame:
        """Carrega dados dos arquivos Excel"""
        logger.info("üîÑ Carregando dados dos arquivos Excel...")
        start_time = time.time()
        
        all_files_raw = glob.glob(f"{self.data_path}/*.xlsx")
        
        # Filtrar arquivos tempor√°rios do Excel
        temp_files = [f for f in all_files_raw if os.path.basename(f).startswith('~$')]
        all_files = [f for f in all_files_raw if not os.path.basename(f).startswith('~$')]
        
        if temp_files:
            logger.info(f"üóëÔ∏è  Ignorando {len(temp_files)} arquivo(s) tempor√°rio(s) do Excel")
        
        logger.info(f"üìÅ Encontrados {len(all_files)} arquivos Excel v√°lidos")
        
        if not all_files:
            raise ValueError("Nenhum arquivo Excel v√°lido encontrado na pasta CicloDetalhado")
        
        df_list = []
        total_rows = 0
        
        for i, filename in enumerate(all_files, 1):
            logger.info(f"üìä Carregando arquivo {i}/{len(all_files)}: {filename}")
            file_start = time.time()
            
            try:
                # Carregar as colunas necess√°rias
                df = pd.read_excel(
                    filename, 
                    usecols=[
                        'DataHoraInicio', 'Tipo Input', 'Massa', 
                        'Tipo de atividade', 'Especificacao de material', 
                        'Material', 'Tag carga', 'Frota carga', 'Frota transporte',
                        'Operando vazio', 'Fila carga', 'Manobra carga', 'Carga',
                        'Operando cheio', 'Fila Descarga', 'Manobra descarga', 'Descarga'
                    ]
                )
                rows = len(df)
                total_rows += rows
                df_list.append(df)
                file_time = time.time() - file_start
                logger.info(f"   ‚úÖ Carregado: {rows:,} linhas em {file_time:.2f}s")
            except Exception as e:
                logger.error(f"   ‚ùå Erro ao carregar {filename}: {e}")
                raise
        
        logger.info(f"üîÄ Combinando {len(df_list)} DataFrames...")
        combine_start = time.time()
        combined_df = pd.concat(df_list, ignore_index=True)
        combine_time = time.time() - combine_start
        
        total_time = time.time() - start_time
        logger.info(f"‚úÖ Dados carregados com sucesso!")
        logger.info(f"   üìà Total de registros: {len(combined_df):,}")
        logger.info(f"   ‚è±Ô∏è  Tempo de combina√ß√£o: {combine_time:.2f}s")
        logger.info(f"   ‚è±Ô∏è  Tempo total: {total_time:.2f}s")
        
        return combined_df
    
    def get_raw_data(self) -> pd.DataFrame:
        """Obt√©m dados brutos com cache inteligente"""
        current_hash = self._get_files_hash()
        current_time = datetime.now()
        
        # Se tem cache v√°lido, usar
        if (self._cache['raw_data'] is not None and 
            self._cache['files_hash'] == current_hash):
            logger.info("‚úÖ Usando dados do cache (arquivos n√£o modificados)")
            return self._cache['raw_data']
        
        logger.info("üîÑ Cache inv√°lido ou inexistente, carregando dados...")
        
        # Carregar dados
        raw_data = self._load_excel_files()
        
        # Atualizar cache
        self._cache['raw_data'] = raw_data
        self._cache['files_hash'] = current_hash
        self._cache['last_check'] = current_time
        logger.info("üíæ Cache atualizado")
        
        return raw_data
    
    def clear_cache(self) -> Dict[str, Any]:
        """Limpa o cache e retorna informa√ß√µes sobre o estado anterior"""
        logger.info("üóëÔ∏è  Limpando cache...")
        
        old_cache = self._cache.copy()
        self._cache['raw_data'] = None
        self._cache['processed_data'] = None
        self._cache['files_hash'] = None
        self._cache['last_check'] = None
        
        had_data = old_cache['raw_data'] is not None
        had_processed = old_cache['processed_data'] is not None
        
        logger.info("‚úÖ Cache limpo com sucesso!")
        
        return {
            'had_raw_data': had_data,
            'had_processed_data': had_processed,
            'timestamp': datetime.now().isoformat()
        }
    
    def get_cache_status(self) -> Dict[str, Any]:
        """Retorna o status atual do cache"""
        return {
            'has_raw_data': self._cache['raw_data'] is not None,
            'has_processed_data': self._cache['processed_data'] is not None,
            'last_check': self._cache['last_check'].isoformat() if self._cache['last_check'] else None,
            'files_hash': self._cache['files_hash'],
            'current_files_hash': self._get_files_hash(),
            'cache_valid': (self._cache['raw_data'] is not None and 
                           self._cache['files_hash'] == self._get_files_hash())
        }
    
    def get_available_tipos_input(self) -> list:
        """Obt√©m valores √∫nicos da coluna 'Tipo Input' para filtros"""
        try:
            df = self.get_raw_data()
            
            if 'Tipo Input' not in df.columns:
                logger.warning("‚ö†Ô∏è Coluna 'Tipo Input' n√£o encontrada nos dados")
                return []
            
            # Obter valores √∫nicos, ordenados e sem valores nulos
            valores_unicos = df['Tipo Input'].dropna().unique().tolist()
            valores_unicos.sort()
            
            logger.info(f"‚úÖ Valores √∫nicos obtidos para 'Tipo Input': {len(valores_unicos)} valores")
            return valores_unicos
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter valores √∫nicos de 'Tipo Input': {str(e)}")
            return []

    def get_available_frota_transporte(self) -> list:
        """Obt√©m valores √∫nicos da coluna 'Frota transporte' para filtros"""
        try:
            df = self.get_raw_data()
            
            if 'Frota transporte' not in df.columns:
                logger.warning("‚ö†Ô∏è Coluna 'Frota transporte' n√£o encontrada nos dados")
                return []
            
            # Obter valores √∫nicos, ordenados e sem valores nulos
            valores_unicos = df['Frota transporte'].dropna().unique().tolist()
            valores_unicos.sort()
            
            logger.info(f"‚úÖ Valores √∫nicos obtidos para 'Frota transporte': {len(valores_unicos)} valores")
            return valores_unicos
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter valores √∫nicos de 'Frota transporte': {str(e)}")
            return []

    def get_available_frota_carga(self) -> list:
        """Obt√©m valores √∫nicos da coluna 'Frota carga' para filtros"""
        try:
            df = self.get_raw_data()
            
            if 'Frota carga' not in df.columns:
                logger.warning("‚ö†Ô∏è Coluna 'Frota carga' n√£o encontrada nos dados")
                return []
            
            # Obter valores √∫nicos, ordenados e sem valores nulos
            valores_unicos = df['Frota carga'].dropna().unique().tolist()
            valores_unicos.sort()
            
            logger.info(f"‚úÖ Valores √∫nicos obtidos para 'Frota carga': {len(valores_unicos)} valores")
            return valores_unicos
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter valores √∫nicos de 'Frota carga': {str(e)}")
            return []

    def get_available_tag_carga(self) -> list:
        """Obt√©m valores √∫nicos da coluna 'Tag carga' para filtros"""
        try:
            df = self.get_raw_data()
            
            if 'Tag carga' not in df.columns:
                logger.warning("‚ö†Ô∏è Coluna 'Tag carga' n√£o encontrada nos dados")
                return []
            
            # Obter valores √∫nicos, ordenados e sem valores nulos
            valores_unicos = df['Tag carga'].dropna().unique().tolist()
            valores_unicos.sort()
            
            logger.info(f"‚úÖ Valores √∫nicos obtidos para 'Tag carga': {len(valores_unicos)} valores")
            return valores_unicos
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter valores √∫nicos de 'Tag carga': {str(e)}")
            return []
